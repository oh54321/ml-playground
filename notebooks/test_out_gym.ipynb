{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b524d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb11c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "\n",
    "import torch\n",
    "from core.environments.gym.env import PolicyEnvironment\n",
    "from core.models.resnet import ResNet\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb64eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/SpaceInvaders-v5\", render_mode=\"rgb_array\")\n",
    "model = ResNet(3 * 3, 6, 2, 2)\n",
    "env_wrapper = PolicyEnvironment(env, 3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ac04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = env_wrapper.sample_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686ee64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations.reinforce.src.buffer import ReinforceReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80f287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = ReinforceReplayBuffer(100, 3, 0.99)\n",
    "buffer.add(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553f5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from gymnasium.core import Env\n",
    "from torch.optim import Optimizer, AdamW\n",
    "import torch.nn as nn\n",
    "from core.environments.gym.trajectory import Trajectory\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "class REINFORCETrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        env: Env,\n",
    "        input_buffer_size: int = 3,\n",
    "        replay_buffer_size: int = 100,\n",
    "        gamma: float = 0.99,\n",
    "        optimizer: Optional[Optimizer] = None\n",
    "    ):\n",
    "        self.env = PolicyEnvironment(env, input_buffer_size, model)\n",
    "        self.model = model\n",
    "        self.gamma = gamma\n",
    "        self.replay = ReinforceReplayBuffer(replay_buffer_size, input_buffer_size, gamma)\n",
    "        if optimizer is None:\n",
    "            self.optimizer = AdamW(model.parameters())\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self._rewards = []\n",
    "\n",
    "    def sample(self) -> Trajectory:\n",
    "        return self.env.sample_trajectory()\n",
    "    \n",
    "    def display(self) -> FuncAnimation:\n",
    "        return self.env.display()\n",
    "\n",
    "    def fetch_output(self):\n",
    "        inputs = self.replay.inputs()\n",
    "        actions = self.replay.actions()\n",
    "        output = torch.log_softmax(self.model.forward(inputs), dim=1)\n",
    "        indices = torch.arange(output.size(0))\n",
    "        future_rewards = self.replay.future_rewards()\n",
    "        values = output[indices, actions] * future_rewards\n",
    "        return values.mean()\n",
    "\n",
    "    def add_reward(self, trajectory: Trajectory):\n",
    "        reward = 0\n",
    "        for node in trajectory.nodes[::-1]:\n",
    "            reward = self.gamma * reward + node.reward\n",
    "        self._rewards.append(reward)\n",
    "        if len(self._rewards) > 10:\n",
    "            print(sum(self._rewards[-10:]) / len(self._rewards[-10:]))\n",
    "\n",
    "    def iterate(self) -> None:\n",
    "        self.replay.reset()\n",
    "        self.optimizer.zero_grad()\n",
    "        while not self.replay.is_full():\n",
    "            trajectory = self.sample()\n",
    "            self.replay.add(trajectory)\n",
    "            self.add_reward(trajectory)\n",
    "        output = self.fetch_output()\n",
    "        output.backward()\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1f3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = REINFORCETrainer(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bddfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver-hayman/anaconda3/envs/ml/lib/python3.11/site-packages/torch/autograd/graph.py:865: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.143938251872036\n",
      "19.70607964766092\n",
      "18.461568655162022\n",
      "18.32754740674404\n",
      "17.976089282537078\n",
      "18.523516767917606\n",
      "18.783318967100247\n",
      "18.111516374672732\n",
      "18.303514671604916\n",
      "19.04943741484066\n",
      "17.05243305326066\n",
      "16.42314476107671\n",
      "16.596279961519624\n",
      "15.37887702607416\n",
      "15.828223098631724\n",
      "16.537486199494495\n",
      "16.19257633994147\n",
      "15.392324887564907\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    trainer.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0791f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53e9b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.module.Module"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91d9a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x796481006260>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08b7ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7100bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = buffer.inputs()\n",
    "actions = buffer.actions()\n",
    "output = torch.log_softmax(model.forward(inputs), dim=1)\n",
    "indices = torch.arange(output.size(0))\n",
    "future_rewards = buffer.future_rewards()\n",
    "values = output[indices, actions] * future_rewards\n",
    "batch_value = values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f6f3561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver-hayman/anaconda3/envs/ml/lib/python3.11/site-packages/torch/autograd/graph.py:865: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "batch_value.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
